{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Movie Data Processing and Preprocessing\n",
    "\n",
    "## Goal\n",
    "\n",
    "The goal is to prepare and preprocess movie-related data to enable downstream tasks such as genre prediction or movie recommendation. To accomplish this, we aim to construct a large, clean, and well-structured dataset by combining and refining two publicly available data sources. This dataset will serve as the foundation for later model training and evaluation using natural language processing techniques.\n",
    "\n",
    "\n",
    "## Datasets Used\n",
    "\n",
    "We use two publicly available datasets from Kaggle:\n",
    "\n",
    "1. **Millions of Movies** (`akshaypawar7/millions-of-movies`):\n",
    "   This dataset contains various metadata about movies, including essential fields like `id`, `title`, `release_date`, `overview`, `genres`, and `recommendations`.\n",
    "   Additionally, it includes other attributes such as `budget`, `revenue`, `runtime`, `popularity`, and `vote_average`, which provide more context but are not critical for our current project goals.\n",
    "\n",
    "2. **Wikipedia Movie Plots** (`jrobischon/wikipedia-movie-plots`): This dataset includes `title`, `release_year`, and detailed plot summaries (`Plot`) for over 34,000 movies.\n",
    "\n",
    "## Data Cleaning and Merging\n",
    "\n",
    "- Titles and release years were cleaned and normalized.\n",
    "- The two datasets were merged using `title` and `release_year` as keys to enrich the primary dataset with additional plot data.\n",
    "- If a plot was missing, we used the overview as a fallback to ensure textual input for each movie.\n",
    "\n",
    "## Additional Cleaning Steps\n",
    "\n",
    "- Removed duplicates using `id` and `title`\n",
    "- Replaced invalid or empty values such as `\"nan\"` or `\"None\"` in the `plot` field\n",
    "\n",
    "## Test Dataset Construction for Recommendations\n",
    "\n",
    "Based on the `recommendations` field, we created two test datasets:\n",
    "\n",
    "- One containing 5,000 movies\n",
    "- One containing 10,000 movies\n",
    "\n",
    "For each movie, we ensured:\n",
    "\n",
    "- A valid plot or overview\n",
    "- That the referenced recommendations exist within the dataset\n",
    "\n",
    "## Exported Files\n",
    "\n",
    "All cleaned and structured datasets were exported as JSON files for further use:\n",
    "\n",
    "- `../data/all_data.json`\n",
    "  Contains the full merged dataset with all available movies, including metadata (such as IDs, titles, release dates, and other attributes), plots, overviews, genres, and recommendations.\n",
    "\n",
    "- `../data/recommendation_with_plot.json`\n",
    "  Contains movies that have both plot information and recommendation data, prepared for recommendation tasks.\n",
    "\n",
    "- `../data/recommendation_with_plot_test_5000.json`\n",
    "  A test dataset subset with 5,000 movies, filtered to ensure valid plots and recommendations for evaluation purposes.\n",
    "\n",
    "- `../data/recommendation_with_plot_test_10000.json`\n",
    "  Similar to the 5,000-movie subset but larger, containing 10,000 movies for testing and validation.\n",
    "\n",
    "- `../data/merged_wiki_plot.json`\n",
    "  Contains only those movie entries for which detailed Wikipedia plot summaries were available and successfully merged, ensuring high-quality, extended plot descriptions.\n"
   ],
   "id": "85702ee46580a78e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T20:00:40.333380Z",
     "start_time": "2025-06-20T20:00:40.330045Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import kagglehub\n",
    "import shutil\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ],
   "id": "e680ee15797b4686",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Download of the Data\n",
    "\n",
    "For this project, we utilize two large publicly available datasets from Kaggle. The first dataset, **Millions of Movies** (`akshaypawar7/millions-of-movies`), contains extensive metadata on over 500,000 movies, including details such as movie IDs, titles, release dates, overviews, genres, and recommendations.\n",
    "\n",
    "The second dataset, **Wikipedia Movie Plots** (`jrobischon/wikipedia-movie-plots`), provides detailed plot summaries for about 34,000 movies. This dataset will be used to enrich the primary dataset with more comprehensive plot descriptions.\n"
   ],
   "id": "34f35c047a7d8323"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T20:00:40.359336Z",
     "start_time": "2025-06-20T20:00:40.356774Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def download_kaggle_dataset(dataset_name):\n",
    "    dataset_path = kagglehub.dataset_download(dataset_name)\n",
    "    target_path = \"data\"\n",
    "    os.makedirs(target_path, exist_ok=True)\n",
    "\n",
    "    for filename in os.listdir(dataset_path):\n",
    "        full_file_name = os.path.join(dataset_path, filename)\n",
    "        if os.path.isfile(full_file_name):\n",
    "            shutil.copy(full_file_name, target_path)\n"
   ],
   "id": "ece72745e4aeeaa5",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T20:00:40.940995Z",
     "start_time": "2025-06-20T20:00:40.367186Z"
    }
   },
   "cell_type": "code",
   "source": "download_kaggle_dataset(\"akshaypawar7/millions-of-movies\")",
   "id": "f8e8a89479d438",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.11), please consider upgrading to the latest version (0.3.12).\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T20:00:44.385257Z",
     "start_time": "2025-06-20T20:00:40.952180Z"
    }
   },
   "cell_type": "code",
   "source": "df = pd.read_csv('data/movies.csv')",
   "id": "c1ec5c7d83509821",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T20:00:45.247308Z",
     "start_time": "2025-06-20T20:00:44.398806Z"
    }
   },
   "cell_type": "code",
   "source": [
    "download_kaggle_dataset(\"jrobischon/wikipedia-movie-plots\")\n",
    "df_wiki = pd.read_csv('data/wiki_movie_plots_deduped.csv')"
   ],
   "id": "d767d74f76471152",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.11), please consider upgrading to the latest version (0.3.12).\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Merging of the Datasets\n",
    "\n",
    "To enrich the movie data with detailed plot descriptions, we merged the **Millions of Movies** dataset with the **Wikipedia Movie Plots** dataset. Since the Wikipedia dataset does not include genre or recommendation information both of which are crucial for our NLP tasks we use it only to supplement the plot data.\n",
    "\n",
    "### Preprocessing Steps Before Merging\n",
    "\n",
    "- **Normalization of Title and Year**:\n",
    "  To ensure accurate matching, we cleaned and normalized the `title` and `release_year` fields in both datasets. This involved:\n",
    "  - Converting titles to lowercase\n",
    "  - Stripping whitespace\n",
    "  - Extracting the release year from the full date string\n",
    "\n",
    "- **Column Renaming for Consistency**:\n",
    "  We renamed relevant columns in the Wikipedia dataset (`Title` → `title`, `Release Year` → `release_year`, `Plot` → `plot_wiki`) to match the naming conventions in the main dataset.\n",
    "\n",
    "### Merge Strategy\n",
    "\n",
    "Since movie titles are not always unique—especially in the case of remakes—we included `release_year` as an additional key when merging the datasets. This increases the likelihood of accurate matches between the two sources.\n",
    "\n",
    "The merge was performed as a **left join** on `title` and `release_year`. This ensures that we retain all records from the primary dataset (`Millions of Movies`), and only add additional plot information if a match is found in the Wikipedia dataset.\n",
    "\n",
    "\n",
    "### Final Dataset\n",
    "\n",
    "We removed duplicates using both the `id` and `title` columns to improve data quality and consistency. The resulting dataset, stored as `merged_wiki_plot`, contains only entries that include:\n",
    "- `id`\n",
    "- `title`\n",
    "- `genres`\n",
    "- `overview`\n",
    "- `plot`\n",
    "\n",
    "This final merged dataset includes **21,287** entries.\n"
   ],
   "id": "c7693f2e4d572255"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T20:00:45.262535Z",
     "start_time": "2025-06-20T20:00:45.258545Z"
    }
   },
   "cell_type": "code",
   "source": "df_wiki.head(3)",
   "id": "564b80912d6a2cfb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Release Year                          Title Origin/Ethnicity Director Cast  \\\n",
       "0          1901         Kansas Saloon Smashers         American  Unknown  NaN   \n",
       "1          1901  Love by the Light of the Moon         American  Unknown  NaN   \n",
       "2          1901        The Martyred Presidents         American  Unknown  NaN   \n",
       "\n",
       "     Genre                                          Wiki Page  \\\n",
       "0  unknown  https://en.wikipedia.org/wiki/Kansas_Saloon_Sm...   \n",
       "1  unknown  https://en.wikipedia.org/wiki/Love_by_the_Ligh...   \n",
       "2  unknown  https://en.wikipedia.org/wiki/The_Martyred_Pre...   \n",
       "\n",
       "                                                Plot  \n",
       "0  A bartender is working at a saloon, serving dr...  \n",
       "1  The moon, painted with a smiling face hangs ov...  \n",
       "2  The film, just over a minute long, is composed...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Release Year</th>\n",
       "      <th>Title</th>\n",
       "      <th>Origin/Ethnicity</th>\n",
       "      <th>Director</th>\n",
       "      <th>Cast</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Wiki Page</th>\n",
       "      <th>Plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1901</td>\n",
       "      <td>Kansas Saloon Smashers</td>\n",
       "      <td>American</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Kansas_Saloon_Sm...</td>\n",
       "      <td>A bartender is working at a saloon, serving dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1901</td>\n",
       "      <td>Love by the Light of the Moon</td>\n",
       "      <td>American</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Love_by_the_Ligh...</td>\n",
       "      <td>The moon, painted with a smiling face hangs ov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1901</td>\n",
       "      <td>The Martyred Presidents</td>\n",
       "      <td>American</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Martyred_Pre...</td>\n",
       "      <td>The film, just over a minute long, is composed...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T20:00:45.469539Z",
     "start_time": "2025-06-20T20:00:45.288115Z"
    }
   },
   "cell_type": "code",
   "source": "df['release_year'] = df['release_date'].apply(lambda x: str(x).split('-')[0] if pd.notnull(x) else None)",
   "id": "4e39c39b9a227535",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T20:00:46.608511Z",
     "start_time": "2025-06-20T20:00:45.513302Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df['title'] = df['title'].astype(str).str.strip().str.lower()\n",
    "df['release_year'] = df['release_year'].astype(str).str.strip()\n",
    "\n",
    "df_wiki.rename(columns={'Title': 'title'}, inplace=True)\n",
    "df_wiki.rename(columns={'Release Year': 'release_year'}, inplace=True)\n",
    "df_wiki.rename(columns={'Plot': 'plot_wiki'}, inplace=True)\n",
    "\n",
    "df_wiki['title'] = df_wiki['title'].astype(str).str.strip().str.lower()\n",
    "df_wiki['release_year'] = df_wiki['release_year'].astype(str).str.strip()\n",
    "\n",
    "plot_info = df_wiki[['title', 'release_year', 'plot_wiki']]\n",
    "\n",
    "df = df.merge(plot_info, on=['title', 'release_year'], how='left', suffixes=('', '_wiki'))\n",
    "\n",
    "if 'plot' in df.columns:\n",
    "    df['plot'] = df['plot_wiki'].combine_first(df['plot'])\n",
    "else:\n",
    "    df['plot'] = df['plot_wiki']\n",
    "\n",
    "df.drop(columns=['plot_wiki'], inplace=True)\n",
    "df = df.drop_duplicates(subset='id', keep='first')\n",
    "df = df.drop_duplicates(subset='title', keep='first')\n"
   ],
   "id": "731c667114f2b9be",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T20:00:46.726847Z",
     "start_time": "2025-06-20T20:00:46.613144Z"
    }
   },
   "cell_type": "code",
   "source": [
    "merged_wiki_plot = df[['id', 'title', 'genres', 'overview', 'plot']].dropna(subset=['id', 'title','genres', 'overview', 'plot'])\n",
    "merged_wiki_plot.shape"
   ],
   "id": "13897eee7626141e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21287, 5)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Creation of Test Datasets\n",
    "\n",
    "Since the full dataset is quite large and may result in long processing times for NLP tasks, we created two smaller test datasets containing approximately 5,000 and 10,000 movies.\n",
    "\n",
    "To ensure that the recommendation functionality works properly, we applied the following criteria:\n",
    "\n",
    "- Only movies with a valid `plot` are included.\n",
    "- Each movie must contain `recommendations`, and all referenced movies must also be present within the dataset.\n",
    "- No duplicate entries are allowed.\n",
    "- A maximum of 20 recommendations per movie is included.\n",
    "\n",
    "After creating the subsets, we ensured that all recommendation IDs within each dataset point to valid movie entries. We did this by filtering out any invalid or non-existent recommendation IDs. Additionally, we replaced missing or invalid `plot` values (e.g., `\"nan\"`, `\"None\"`, or empty strings) with the corresponding `overview` to ensure every entry has usable text.\n",
    "\n",
    "These final cleaning steps guarantee that:\n",
    "\n",
    "- The recommendation references are internally consistent.\n",
    "- All entries contain valid textual descriptions.\n",
    "- The datasets are ready for downstream NLP applications such as content-based recommendation or genre prediction.\n",
    "\n"
   ],
   "id": "382b63a02ac7d7d8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T20:00:46.745350Z",
     "start_time": "2025-06-20T20:00:46.741307Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def build_expanded_dataset(test_df, target_size=5000):\n",
    "    test_df = test_df.dropna(subset=['id', 'recommendations']).copy()\n",
    "\n",
    "    def parse_recommendations(val):\n",
    "        if isinstance(val, str):\n",
    "            return [int(x) for x in val.split('-') if x.isdigit()]\n",
    "        elif isinstance(val, int):\n",
    "            return [val]\n",
    "        elif isinstance(val, list):\n",
    "            return val\n",
    "        else:\n",
    "            return []\n",
    "\n",
    "    test_df['parsed_recommendations'] = test_df['recommendations'].apply(parse_recommendations)\n",
    "    test_df = test_df.drop_duplicates(subset='id')\n",
    "\n",
    "    id_map = test_df.set_index('id').to_dict(orient='index')\n",
    "\n",
    "    result_ids = set()\n",
    "    visited_ids = set()\n",
    "\n",
    "    start_ids = test_df[test_df['plot'].notna()]['id'].tolist()\n",
    "    idx = 0\n",
    "\n",
    "    while len(result_ids) < target_size and idx < len(start_ids):\n",
    "        current_id = start_ids[idx]\n",
    "        idx += 1\n",
    "\n",
    "        if current_id in visited_ids:\n",
    "            continue\n",
    "\n",
    "        visited_ids.add(current_id)\n",
    "        result_ids.add(current_id)\n",
    "\n",
    "        recs = id_map.get(current_id, {}).get('parsed_recommendations', [])\n",
    "\n",
    "        added = 0\n",
    "        for rec_id in recs:\n",
    "            if rec_id in id_map and rec_id not in result_ids:\n",
    "                result_ids.add(rec_id)\n",
    "                added += 1\n",
    "                if added >= 20:\n",
    "                    break\n",
    "\n",
    "    result_test_df = test_df[test_df['id'].isin(result_ids)].drop_duplicates(subset='id').copy()\n",
    "\n",
    "    result_test_df['recommendations'] = result_test_df['parsed_recommendations'].apply(\n",
    "        lambda recs: '-'.join(str(r) for r in recs)\n",
    "    )\n",
    "\n",
    "    result_test_df.drop(columns=['parsed_recommendations'], inplace=True)\n",
    "\n",
    "    return result_test_df\n"
   ],
   "id": "a91f5d767e54e8e3",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T20:00:47.502440Z",
     "start_time": "2025-06-20T20:00:46.767940Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_recommendation_with_plot_test_5000 = build_expanded_dataset(df, target_size=5000)\n",
    "print(df_recommendation_with_plot_test_5000.shape)\n",
    "\n",
    "df_recommendation_with_plot_test_10000 = build_expanded_dataset(df, target_size=10000)\n",
    "print(df_recommendation_with_plot_test_10000.shape)\n"
   ],
   "id": "b8f978add49f45ed",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5003, 22)\n",
      "(10000, 22)\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T20:00:47.538608Z",
     "start_time": "2025-06-20T20:00:47.504948Z"
    }
   },
   "cell_type": "code",
   "source": [
    "valid_ids_5000 = set(df_recommendation_with_plot_test_5000['id'].astype(str))\n",
    "\n",
    "valid_ids_10000 = set(df_recommendation_with_plot_test_10000['id'].astype(str))\n",
    "\n",
    "def filter_recommendations(rec_str, valid_ids):\n",
    "    rec_list = rec_str.split('-')\n",
    "    filtered = [r for r in rec_list if r in valid_ids]\n",
    "    return '-'.join(filtered)\n",
    "\n",
    "df_recommendation_with_plot_test_5000['recommendations'] = (\n",
    "    df_recommendation_with_plot_test_5000['recommendations'].astype(str)\n",
    "    .apply(filter_recommendations, args=(valid_ids_5000,))\n",
    ")\n",
    "\n",
    "df_recommendation_with_plot_test_10000['recommendations'] = (\n",
    "    df_recommendation_with_plot_test_10000['recommendations'].astype(str)\n",
    "    .apply(filter_recommendations, args=(valid_ids_10000,))\n",
    ")\n"
   ],
   "id": "e7429039f70ae92d",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T20:00:47.558688Z",
     "start_time": "2025-06-20T20:00:47.554546Z"
    }
   },
   "cell_type": "code",
   "source": [
    "(df_recommendation_with_plot_test_5000['recommendations'].isna() | (df_recommendation_with_plot_test_5000['recommendations'] == '')).sum()\n",
    "(df_recommendation_with_plot_test_10000['recommendations'].isna() | (df_recommendation_with_plot_test_10000['recommendations'] == '')).sum()"
   ],
   "id": "cc03d7fed28ad0b5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "206"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T20:00:47.810328Z",
     "start_time": "2025-06-20T20:00:47.574150Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df['plot'] = df['plot'].astype(str)\n",
    "df['plot'] = df['plot'].replace([\"nan\", \"None\", \"\"], pd.NA).fillna(df['overview'])\n",
    "df['recommendations'] = df['recommendations'].astype(str)\n",
    "\n",
    "df_recommendation_with_plot_test_5000['plot'] = df_recommendation_with_plot_test_5000['plot'].astype(str)\n",
    "\n",
    "df_recommendation_with_plot_test_5000['plot'] = df_recommendation_with_plot_test_5000['plot'].astype(str)\n",
    "df_recommendation_with_plot_test_5000['recommendations'] = df_recommendation_with_plot_test_5000['recommendations'].astype(str)\n",
    "\n",
    "df_recommendation_with_plot_test_5000['plot'] = df_recommendation_with_plot_test_5000['plot'].replace([\"nan\", \"None\", \"\"], pd.NA).fillna(df_recommendation_with_plot_test_5000['overview'])\n",
    "\n",
    "print(df_recommendation_with_plot_test_5000.isna().sum())\n",
    "print(df_recommendation_with_plot_test_5000.shape)\n",
    "\n",
    "df_recommendation_with_plot_test_10000['plot'] = df_recommendation_with_plot_test_10000['plot'].astype(str)\n",
    "\n",
    "df_recommendation_with_plot_test_10000['plot'] = df_recommendation_with_plot_test_10000['plot'].astype(str)\n",
    "df_recommendation_with_plot_test_10000['recommendations'] = df_recommendation_with_plot_test_10000['recommendations'].astype(str)\n",
    "\n",
    "df_recommendation_with_plot_test_10000['plot'] = df_recommendation_with_plot_test_10000['plot'].replace([\"nan\", \"None\", \"\"], pd.NA).fillna(df_recommendation_with_plot_test_10000['overview'])"
   ],
   "id": "94d9f05ae28507fe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                        0\n",
      "title                     0\n",
      "genres                    9\n",
      "original_language         0\n",
      "overview                 16\n",
      "popularity                0\n",
      "production_companies    146\n",
      "release_date              0\n",
      "budget                    0\n",
      "revenue                   0\n",
      "runtime                   1\n",
      "status                    0\n",
      "tagline                 896\n",
      "vote_average              0\n",
      "vote_count                0\n",
      "credits                  17\n",
      "keywords                360\n",
      "poster_path               5\n",
      "backdrop_path            59\n",
      "recommendations           0\n",
      "release_year              0\n",
      "plot                     15\n",
      "dtype: int64\n",
      "(5003, 22)\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T20:00:48.025407Z",
     "start_time": "2025-06-20T20:00:47.824584Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_recommendation_with_plot = df.dropna(subset=['id', 'title', 'overview'])[['id', 'title', 'overview', 'recommendations', 'plot', 'genres']]\n",
    "\n",
    "df_recommendation_with_plot_test_5000 = df_recommendation_with_plot_test_5000.dropna(subset=['id', 'title', 'overview'])[['id', 'title', 'overview', 'recommendations', 'plot', 'genres']]\n",
    "\n",
    "df_recommendation_with_plot_test_10000 = df_recommendation_with_plot_test_10000.dropna(subset=['id', 'title', 'overview'])[['id', 'title', 'overview', 'recommendations', 'plot', 'genres']]\n"
   ],
   "id": "2d1eb32b7bfbf92e",
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Exporting Final Datasets\n",
    "\n",
    "After cleaning, merging, and filtering the data, all final datasets were exported as JSON files for further use in downstream NLP tasks and recommendation systems.\n",
    "\n",
    "The following files were generated:\n",
    "\n",
    "- `../data/all_data.json`: Contains the full cleaned dataset with metadata, plots, and recommendations. This includes some entries without full plot information but is useful for broader analyses.\n",
    "- `../data/recommendation_with_plot.json`: A subset of the full dataset including only movies that contain all relevant fields (`id`, `title`, `overview`, `plot`, `genres`, and `recommendations`).\n",
    "- `../data/recommendation_with_plot_test_5000.json`: A compact dataset with approximately 5,000 entries, cleaned and filtered to maintain valid recommendation links and non-empty plots. Ideal for quick experimentation.\n",
    "- `../data/recommendation_with_plot_test_10000.json`: A larger test dataset with about 10,000 entries, following the same quality criteria as the 5k set.\n",
    "- `../data/merged_wiki_plot.json`: Includes only the movies that were successfully merged with the Wikipedia dataset and contain enriched plot information.\n",
    "\n",
    "These exports ensure the datasets are readily available in a structured format and can be easily loaded for modeling, evaluation, and other analysis steps.\n"
   ],
   "id": "7701eb76972f745b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T20:00:54.276162Z",
     "start_time": "2025-06-20T20:00:48.036880Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df.to_json('../data/all_data.json', orient='records', lines=True)\n",
    "df_recommendation_with_plot.to_json('../data/recommendation_with_plot.json', orient='records', lines=True)\n",
    "df_recommendation_with_plot_test_5000.to_json('../data/recommendation_with_plot_test_5000.json', orient='records', lines=True)\n",
    "df_recommendation_with_plot_test_10000.to_json('../data/recommendation_with_plot_test_10000.json', orient='records', lines=True)\n",
    "\n",
    "merged_wiki_plot.to_json('../data/merged_wiki_plot.json', orient='records', lines=True)"
   ],
   "id": "a7906772c7622f69",
   "outputs": [],
   "execution_count": 53
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
